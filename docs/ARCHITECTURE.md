# Aurora Life Compass - Architektura

## PrzeglÄ…d

Aurora Life Compass to zaawansowany osobisty "silnik predykcji Å¼ycia", ktÃ³ry buduje cyfrowego bliÅºniaka uÅ¼ytkownika i wykorzystuje AI do optymalizacji decyzji Å¼yciowych.

## Status implementacji

### âœ… Zestaw 1 - Fundamenty (GOTOWE)

Wszystkie podstawowe moduÅ‚y sÄ… zaimplementowane i dziaÅ‚ajÄ…:

1. **Core Identity Layer** - Cyfrowy bliÅºniak uÅ¼ytkownika
2. **Life Event Stream (LES)** - System rejestracji zdarzeÅ„ Å¼yciowych
3. **Behavioral Timeline Engine** - Analiza wzorcÃ³w i cykli
4. **Data Vault** - Bezpieczne przechowywanie danych

### ðŸ”œ Zestaw 2 - Sztuczna Inteligencja Å»ycia (PLANOWANE)

- Aurora Agents (7 agentÃ³w AI)
- DataGenius (zaawansowane ML/DS)
- What-If Engine (symulacje scenariuszy)
- Life Reinforcement System (uczenie ze wzmocnieniem)

### ðŸ”œ Zestaw 3 - Orkiestracja (PLANOWANE)

- FlowOS-style Orchestrator
- LLM Integration Hub (OpenAI/Claude)
- External API Integrations
- UI Dashboard

---

## Architektura techniczna

### Stack technologiczny

```
Backend:
â”œâ”€â”€ FastAPI (Python 3.11+)
â”œâ”€â”€ SQLAlchemy (async ORM)
â”œâ”€â”€ PostgreSQL (JSONB dla flexibility)
â”œâ”€â”€ Redis Streams (real-time events)
â”œâ”€â”€ Pydantic (validation)
â””â”€â”€ NumPy/Pandas (analityka)

PrzyszÅ‚oÅ›Ä‡ (Zestaw 2-3):
â”œâ”€â”€ scikit-learn, TensorFlow/PyTorch (ML)
â”œâ”€â”€ OpenAI/Anthropic API (LLM)
â”œâ”€â”€ React/Next.js (UI)
â””â”€â”€ Docker/K8s (deployment)
```

### Struktura projektu

```
aurora-life-compass/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/                    # ModuÅ‚y biznesowe
â”‚   â”‚   â”‚   â”œâ”€â”€ identity/           # Core Identity Layer
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ service.py      # ZarzÄ…dzanie profilem uÅ¼ytkownika
â”‚   â”‚   â”‚   â”œâ”€â”€ events/             # Life Event Stream
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ service.py      # CRUD dla zdarzeÅ„
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ stream.py       # Redis Streams manager
â”‚   â”‚   â”‚   â”œâ”€â”€ timeline/           # Behavioral Timeline Engine
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ service.py      # CRUD dla timeline
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ analyzer.py     # Pattern detection
â”‚   â”‚   â”‚   â””â”€â”€ vault/              # Data Vault
â”‚   â”‚   â”‚       â””â”€â”€ service.py      # Export, archiwizacja
â”‚   â”‚   â”œâ”€â”€ api/                    # REST API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ users.py
â”‚   â”‚   â”‚   â”œâ”€â”€ events.py
â”‚   â”‚   â”‚   â”œâ”€â”€ timeline.py
â”‚   â”‚   â”‚   â””â”€â”€ vault.py
â”‚   â”‚   â”œâ”€â”€ models/                 # Database models (SQLAlchemy)
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ life_event.py
â”‚   â”‚   â”‚   â””â”€â”€ timeline.py
â”‚   â”‚   â”œâ”€â”€ schemas/                # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ database.py             # Database setup
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI app
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docs/                           # Dokumentacja
â””â”€â”€ docker-compose.yml
```

---

## ModuÅ‚y podstawowe (Zestaw 1)

### 1. Core Identity Layer

**Cel**: ZarzÄ…dzanie cyfrowym bliÅºniakiem uÅ¼ytkownika

**Komponenty**:
- `User` model - podstawowe dane + profile_data (JSONB)
- `IdentityService` - logika biznesowa
- Metryki Å¼yciowe: health_score, energy_score, mood_score, productivity_score

**API Endpoints**:
```
POST   /api/users              - UtwÃ³rz uÅ¼ytkownika
GET    /api/users/{id}         - Pobierz profil
PUT    /api/users/{id}         - Aktualizuj profil
GET    /api/users/{id}/digital-twin - PeÅ‚ny cyfrowy bliÅºniak
```

**Dane przechowywane**:
```json
{
  "goals": ["ZwiÄ™kszyÄ‡ produktywnoÅ›Ä‡", "PoprawiÄ‡ zdrowie"],
  "values": ["rodzina", "rozwÃ³j", "zdrowie"],
  "preferences": {
    "work_hours": "9-17",
    "sleep_target": 8
  },
  "life_state": {
    "health": {},
    "relationships": {},
    "finances": {},
    "career": {},
    "personal_growth": {}
  }
}
```

---

### 2. Life Event Stream (LES)

**Cel**: Rejestracja wszystkich zdarzeÅ„ Å¼yciowych w czasie rzeczywistym

**Komponenty**:
- `LifeEvent` model - elastyczna struktura (event_data jako JSONB)
- `LifeEventService` - CRUD operacje
- `EventStreamManager` - Redis Streams dla real-time processing

**Typy zdarzeÅ„**:
- `sleep` - sen
- `activity`, `exercise` - aktywnoÅ›Ä‡ fizyczna
- `emotion` - emocje, nastrÃ³j
- `work` - praca, zadania
- `social` - interakcje spoÅ‚eczne
- `health` - zdrowie
- `finance` - finanse

**API Endpoints**:
```
POST   /api/events             - UtwÃ³rz zdarzenie
GET    /api/events             - Lista zdarzeÅ„ (filtry: type, days)
GET    /api/events/{id}        - Pobierz zdarzenie
PUT    /api/events/{id}        - Aktualizuj zdarzenie
DELETE /api/events/{id}        - UsuÅ„ zdarzenie
GET    /api/events/stats/summary - Statystyki
```

**PrzykÅ‚ad zdarzenia**:
```json
{
  "event_type": "sleep",
  "title": "Nocny sen",
  "event_time": "2025-11-24T23:00:00Z",
  "duration_minutes": 450,
  "event_data": {
    "quality": 8,
    "deep_sleep_minutes": 120,
    "rem_minutes": 90
  },
  "tags": ["regular", "good_quality"]
}
```

**Redis Streams**:
- Stream name: `aurora:life_events`
- Consumer group: `aurora_processors`
- Real-time publikowanie kaÅ¼dego zdarzenia
- Podstawa do przyszÅ‚ych agentÃ³w AI (Zestaw 2)

---

### 3. Behavioral Timeline Engine

**Cel**: Wykrywanie wzorcÃ³w, cykli, anomalii i trendÃ³w z life events

**Komponenty**:
- `TimelineEntry` model - przetworzone insights
- `TimelineService` - CRUD dla timeline
- `PatternAnalyzer` - algorytmy wykrywania wzorcÃ³w

**Typy wpisÃ³w timeline**:
- `pattern` - wykryty wzorzec (np. regularny sen)
- `cycle` - cykl (rytm Å¼yciowy)
- `anomaly` - anomalia (odstÄ™pstwo od normy)
- `trend` - trend (wzrost/spadek w czasie)
- `milestone` - kamieÅ„ milowy
- `insight` - wygenerowany insight

**API Endpoints**:
```
POST   /api/timeline           - UtwÃ³rz wpis
GET    /api/timeline           - Lista wpisÃ³w
GET    /api/timeline/patterns/detect - Wykryj wzorce
GET    /api/timeline/insights/recent - Ostatnie insights
GET    /api/timeline/summary/period  - Podsumowanie
```

**Algorytmy wykrywania (PatternAnalyzer)**:

1. **Sleep Pattern Detection**
   - Åšrednia dÅ‚ugoÅ›Ä‡ snu
   - RegularnoÅ›Ä‡ (odchylenie standardowe)
   - Preferowana pora snu
   - Confidence score

2. **Activity Pattern Detection**
   - CzÄ™stotliwoÅ›Ä‡ aktywnoÅ›ci
   - Preferowane dni tygodnia
   - Consistency score

3. **Anomaly Detection**
   - Z-score detection (>2Ïƒ)
   - Identyfikacja wartoÅ›ci odstajÄ…cych

4. **Trend Detection**
   - Regresja liniowa
   - Kierunek trendu (improving/declining/stable)
   - RÂ² confidence

**PrzykÅ‚ad wzorca**:
```json
{
  "type": "sleep_cycle",
  "avg_duration_hours": 7.5,
  "regularity_score": 0.85,
  "avg_bedtime_hour": 23.0,
  "confidence": 0.92
}
```

---

### 4. Data Vault

**Cel**: Bezpieczne przechowywanie i zarzÄ…dzanie peÅ‚nÄ… historiÄ… Å¼ycia

**Komponenty**:
- `DataVaultService` - eksport, statystyki, usuwanie danych

**Funkcje**:
1. **Export uÅ¼ytkownika** (GDPR compliance)
   - PeÅ‚ny eksport profilu + events + timeline
   - Format JSON
   - Filtry czasowe

2. **Statystyki**
   - Liczba zdarzeÅ„, wpisÃ³w timeline
   - RozkÅ‚ad typÃ³w zdarzeÅ„
   - Okres Å›ledzenia

3. **Usuwanie danych** (GDPR right to erasure)
   - Kasowanie events, timeline
   - Opcjonalne usuniÄ™cie konta

4. **Archiwizacja**
   - Identyfikacja starych danych (>365 dni)
   - Placeholder dla cold storage

**API Endpoints**:
```
GET    /api/vault/export/{user_id}   - Eksport danych
GET    /api/vault/summary/{user_id}  - Podsumowanie
DELETE /api/vault/user/{user_id}     - UsuÅ„ dane (GDPR)
GET    /api/vault/archive/{user_id}  - Info o archiwizacji
```

---

## Baza danych

### PostgreSQL Schema

**users** - Profile uÅ¼ytkownikÃ³w
```sql
id              SERIAL PRIMARY KEY
email           VARCHAR UNIQUE NOT NULL
username        VARCHAR UNIQUE NOT NULL
hashed_password VARCHAR NOT NULL
full_name       VARCHAR
date_of_birth   TIMESTAMP
timezone        VARCHAR DEFAULT 'UTC'
profile_data    JSONB DEFAULT '{}'
health_score    FLOAT DEFAULT 0.0
energy_score    FLOAT DEFAULT 0.0
mood_score      FLOAT DEFAULT 0.0
productivity_score FLOAT DEFAULT 0.0
settings        JSONB DEFAULT '{}'
created_at      TIMESTAMP DEFAULT NOW()
updated_at      TIMESTAMP
last_active     TIMESTAMP
```

**life_events** - Zdarzenia Å¼yciowe
```sql
id              SERIAL PRIMARY KEY
user_id         INTEGER NOT NULL REFERENCES users(id)
event_type      VARCHAR NOT NULL
event_category  VARCHAR
title           VARCHAR NOT NULL
description     VARCHAR
event_data      JSONB DEFAULT '{}'
event_time      TIMESTAMP NOT NULL
duration_minutes INTEGER
end_time        TIMESTAMP
impact_score    FLOAT
energy_impact   FLOAT
mood_impact     FLOAT
tags            JSONB DEFAULT '[]'
context         JSONB DEFAULT '{}'
source          VARCHAR DEFAULT 'manual'
created_at      TIMESTAMP DEFAULT NOW()
updated_at      TIMESTAMP

INDEX idx_user_event_time (user_id, event_time)
INDEX idx_user_event_type_time (user_id, event_type, event_time)
```

**timeline_entries** - OÅ› czasu z wzorcami
```sql
id              SERIAL PRIMARY KEY
user_id         INTEGER NOT NULL REFERENCES users(id)
entry_type      VARCHAR NOT NULL
start_time      TIMESTAMP NOT NULL
end_time        TIMESTAMP NOT NULL
title           VARCHAR NOT NULL
description     VARCHAR
analysis_data   JSONB DEFAULT '{}'
confidence_score FLOAT
importance_score FLOAT
related_event_ids JSONB DEFAULT '[]'
is_recurring    BOOLEAN DEFAULT FALSE
is_significant  BOOLEAN DEFAULT FALSE
tags            JSONB DEFAULT '[]'
created_at      TIMESTAMP DEFAULT NOW()
updated_at      TIMESTAMP

INDEX idx_user_timeline_time (user_id, start_time)
INDEX idx_user_timeline_type (user_id, entry_type)
```

### Redis

**Streams**:
- `aurora:life_events` - Stream zdarzeÅ„ Å¼yciowych
- Consumer group: `aurora_processors`

**Struktura wiadomoÅ›ci**:
```json
{
  "event_id": "123",
  "user_id": "456",
  "event_type": "sleep",
  "event_time": "2025-11-24T23:00:00Z",
  "data": "{...}",
  "published_at": "2025-11-25T07:00:00Z"
}
```

---

## PrzepÅ‚yw danych

### 1. Rejestracja zdarzenia

```
User â†’ POST /api/events
  â†“
LifeEventService.create_event()
  â†“
PostgreSQL: INSERT life_events
  â†“
EventStreamManager.publish_event()
  â†“
Redis Stream: aurora:life_events
  â†“
[PrzyszÅ‚oÅ›Ä‡: Aurora Agents konsumujÄ… stream]
```

### 2. Analiza wzorcÃ³w

```
User â†’ GET /api/timeline/patterns/detect?days=30
  â†“
LifeEventService.get_recent_events()
  â†“
PatternAnalyzer.detect_*_pattern()
  â†“
ZwrÃ³Ä‡ wykryte wzorce
```

### 3. Eksport danych (GDPR)

```
User â†’ GET /api/vault/export/{user_id}
  â†“
DataVaultService.export_user_data()
  â†“
Query: users + life_events + timeline_entries
  â†“
ZwrÃ³Ä‡ kompletny JSON export
```

---

## BezpieczeÅ„stwo

### Obecnie zaimplementowane:
- Haszowanie haseÅ‚ (bcrypt via passlib)
- CORS middleware
- Environment variables dla sekretÃ³w

### Planowane (Zestaw 3):
- JWT authentication
- Role-based access control
- Rate limiting
- Encryption at rest (sensitive data)
- Audit logging

---

## Skalowanie

### Obecna architektura:
- Async PostgreSQL (asyncpg)
- Redis Streams dla real-time processing
- Horizontally scalable (stateless API)

### PrzyszÅ‚e optymalizacje:
- Read replicas dla PostgreSQL
- Redis Cluster
- Caching layer (Redis)
- Message queue dla dÅ‚ugich zadaÅ„ (Celery)
- Vector database dla embeddings (Pinecone/FAISS)

---

## Roadmap

### âœ… Faza 1 - Fundamenty (GOTOWE)
- Core Identity Layer
- Life Event Stream
- Behavioral Timeline Engine
- Data Vault
- REST API
- Docker setup

### ðŸ”œ Faza 2 - Sztuczna Inteligencja (Q1 2026)
- **DataGenius**: ML models dla predykcji
- **Aurora Agents**: 7 wyspecjalizowanych agentÃ³w AI
- **What-If Engine**: Symulacje scenariuszy
- **Life Reinforcement System**: Deep Q-Learning

### ðŸ”œ Faza 3 - Orkiestracja (Q2 2026)
- **FlowOS Orchestrator**: Multi-agent coordination
- **LLM Integration**: OpenAI/Claude API
- **External APIs**: Google Calendar, Wearables, etc.
- **UI Dashboard**: React/Next.js interface

### ðŸ”œ Faza 4 - Production (Q3 2026)
- Authentication & Authorization
- Advanced security
- Monitoring & Observability
- CI/CD pipeline
- Production deployment

---

## PrzykÅ‚ady uÅ¼ycia

### Scenariusz 1: Nowy uÅ¼ytkownik

```bash
# 1. UtwÃ³rz uÅ¼ytkownika
curl -X POST http://localhost:8000/api/users \
  -H "Content-Type: application/json" \
  -d '{
    "email": "jan@example.com",
    "username": "jan",
    "password": "secure123",
    "full_name": "Jan Kowalski",
    "timezone": "Europe/Warsaw"
  }'

# 2. Dodaj zdarzenie snu
curl -X POST "http://localhost:8000/api/events?user_id=1" \
  -H "Content-Type: application/json" \
  -d '{
    "event_type": "sleep",
    "title": "Nocny sen",
    "event_time": "2025-11-24T23:00:00Z",
    "duration_minutes": 480,
    "event_data": {
      "quality": 9,
      "deep_sleep_minutes": 140
    }
  }'

# 3. Pobierz ostatnie zdarzenia
curl "http://localhost:8000/api/events?user_id=1&days=7"

# 4. Wykryj wzorce (po zebraniu danych)
curl "http://localhost:8000/api/timeline/patterns/detect?user_id=1&days=30"
```

### Scenariusz 2: Analiza wzorcÃ³w Å¼yciowych

Po 30 dniach zbierania danych:
- System automatycznie wykrywa regularny wzorzec snu (23:00-7:00)
- Identyfikuje preferowane dni na aktywnoÅ›Ä‡ (wtorek, czwartek, sobota)
- Wykrywa anomalie (np. krÃ³tki sen w piÄ…tek)
- Generuje trend energii (wzrost o 15% w ostatnim miesiÄ…cu)

---

## Referencje

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [SQLAlchemy Async](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [Redis Streams](https://redis.io/docs/data-types/streams/)
- [Pydantic](https://docs.pydantic.dev/)
